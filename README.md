# Visual Question Answering Papers

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(1).pdf" style="text-decoration:none;">Towards a Visual Turing Challenge</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(2).pdf" style="text-decoration:none;">Object-Centric Diagnosis of Visual Reasoning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(3).pdf" style="text-decoration:none;">Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(4).pdf" style="text-decoration:none;">Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(5).pdf" style="text-decoration:none;">UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(6).pdf" style="text-decoration:none;">ConceptBert: Concept-Aware Representation for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(7).pdf" style="text-decoration:none;">VinVL: Revisiting Visual Representations in Vision-Language Models</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(8).pdf" style="text-decoration:none;"> Understanding the Role of Scene Graphs in Visual Question Answering </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(9).pdf" style="text-decoration:none;">Recent Advances in Video Question Answering: A Review of Datasets and Methods</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(10).pdf" style="text-decoration:none;">Reasoning over Vision and Language: Exploring the Benefits of Supplemental Knowledge </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(11).pdf" style="text-decoration:none;">Latent Variable Models for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(12).pdf" style="text-decoration:none;">Visual Question Answering based on Local-Scene-Aware Referring Expression Generation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(13).pdf" style="text-decoration:none;">Answer Questions with Right Image Regions: A Visual Attention Regularization Approach</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(14).pdf" style="text-decoration:none;">Improving Visual Reasoning by Exploiting The Knowledge in Texts</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(15).pdf" style="text-decoration:none;">Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(16).pdf" style="text-decoration:none;">Unanswerable Questions about Images and Texts</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(17).pdf" style="text-decoration:none;">SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(18).pdf" style="text-decoration:none;">Learning Compositional Representation for Few-shot Visual Question Answering</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(19).pdf" style="text-decoration:none;">Visual Turing test for computer vision systems</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(20).pdf" style="text-decoration:none;">Image-Question-Linguistic Co-Attention for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(21).pdf" style="text-decoration:none;">Co-Attention Network With Question Type for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(22).pdf" style="text-decoration:none;">CGMVQA: A New Classification and Generative Model for Medical Visual Question Answering</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(23).pdf" style="text-decoration:none;">Counterfactual Vision and Language Learning</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(24).pdf" style="text-decoration:none;">Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(25).pdf" style="text-decoration:none;">Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(26).pdf" style="text-decoration:none;">Question-Guided Hybrid Convolution for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(27).pdf" style="text-decoration:none;">IQA: Visual Question Answering in Interactive Environments</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(28).pdf" style="text-decoration:none;">TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(29).pdf" style="text-decoration:none;">An Analysis of Visual Question Answering Algorithms </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(30).pdf" style="text-decoration:none;">Answer-Type Prediction for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(31).pdf" style="text-decoration:none;">DVQA: Understanding Data Visualizations via Question Answering</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(32).pdf" style="text-decoration:none;">How clever is the FiLM model, and how clever can it be?</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(33).pdf" style="text-decoration:none;">Visual Question Answering as Reading Comprehension</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(34).pdf" style="text-decoration:none;">12-in-1: Multi-Task Vision and Language Representation Learning</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(35).pdf" style="text-decoration:none;">Object-difference drived graph convolutional networks for visual question answering</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(36).pdf" style="text-decoration:none;">Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(37).pdf" style="text-decoration:none;">Chain of Reasoning for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(38).pdf" style="text-decoration:none;">Learning Conditioned Graph Structures for Interpretable Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(39).pdf" style="text-decoration:none;">ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(40).pdf" style="text-decoration:none;">Visual Question Answering with Question Representation Update (QRU)</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(41).pdf" style="text-decoration:none;">Multimodal Learning and Reasoning for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(42).pdf" style="text-decoration:none;">SQuINTing at VQA Models:
Introspecting VQA Models with Sub-Questions</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(43).pdf" style="text-decoration:none;">Learning Visual Knowledge Memory Networks for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(44).pdf" style="text-decoration:none;">VQA with No Questions-Answers Training</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(45).pdf" style="text-decoration:none;">Data Augmentation for Visual Question Answering</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(46).pdf" style="text-decoration:none;">Visual Commonsense R-CNN</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(47).pdf" style="text-decoration:none;">TA-Student VQA: Multi-Agents Training by Self-Questioning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(48).pdf" style="text-decoration:none;">Deep Attention Neural Tensor Network for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(49).pdf" style="text-decoration:none;">Multi-level Attention Networks for Visual Question Answering</a></li>
 


                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(1).pdf" style="text-decoration:none;">Information fusion in visual question answering: A Survey</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(2).pdf" style="text-decoration:none;">Feature Enhancement in Attention for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(3).pdf" style="text-decoration:none;">A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(4).pdf" style="text-decoration:none;">Hard to Cheat: A Turing Test based on Answering Questions about Images</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(5).pdf" style="text-decoration:none;">VQA: Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(6).pdf" style="text-decoration:none;">Ask Your Neurons: A Neural-based Approach to Answering Questions about Images</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(7).pdf" style="text-decoration:none;">Exploring Models and Data for Image Question Answering</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(8).pdf" style="text-decoration:none;"> Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(9).pdf" style="text-decoration:none;">Visual Madlibs: Fill in the blank Image Generation and Question Answering</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(10).pdf" style="text-decoration:none;">Learning to Answer Questions From Image Using Convolutional Neural Network </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(11).pdf" style="text-decoration:none;">What Value Do Explicit High Level Concepts Have in Vision to Language Problems?</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(12).pdf" style="text-decoration:none;">Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(13).pdf" style="text-decoration:none;">Stacked Attention Networks for Image Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(14).pdf" style="text-decoration:none;">Explicit Knowledge-based Reasoning for Visual Question Answering</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(15).pdf" style="text-decoration:none;">Deep Compositional Question Answering with Neural Module Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(16).pdf" style="text-decoration:none;">Visual7W: Grounded Question Answering in Images</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(17).pdf" style="text-decoration:none;">Yin and Yang: Balancing and Answering Binary Visual Questions</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(18).pdf" style="text-decoration:none;">Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(19).pdf" style="text-decoration:none;">Compositional Memory for Visual Question Answering</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(20).pdf" style="text-decoration:none;">Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(21).pdf" style="text-decoration:none;">ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(22).pdf" style="text-decoration:none;">Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(23).pdf" style="text-decoration:none;">Where To Look: Focus Regions for Visual Question Answering</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(24).pdf" style="text-decoration:none;">Simple Baseline for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(25).pdf" style="text-decoration:none;">Learning to Compose Neural Networks for Question Answering</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(26).pdf" style="text-decoration:none;">Visual Genome: 
Connecting Language and Vision Using Crowdsourced Dense Image Annotations</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(27).pdf" style="text-decoration:none;">Dynamic Memory Networks for Visual and Textual Question Answering</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(28).pdf" style="text-decoration:none;">Image Captioning and Visual Question Answering Based on Attributes and External Knowledge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(29).pdf" style="text-decoration:none;">A Diagram Is Worth A Dozen Images </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(30).pdf" style="text-decoration:none;">A Focused Dynamic Attention Model for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(31).pdf" style="text-decoration:none;">Counting Everyday Objects in Everyday Scenes</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(32).pdf" style="text-decoration:none;">Hierarchical Question-Image Co-Attention for Visual Question Answering</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(33).pdf" style="text-decoration:none;">Multimodal Residual Learning for Visual QA</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(34).pdf" style="text-decoration:none;">Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(35).pdf" style="text-decoration:none;">Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(36).pdf" style="text-decoration:none;">Training Recurrent Answering Units with Joint Loss Minimization for VQA</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(37).pdf" style="text-decoration:none;">FVQA: Fact-based Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(38).pdf" style="text-decoration:none;">DualNet: Domain-Invariant Network for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(39).pdf" style="text-decoration:none;">Revisiting Visual Question Answering Baselines</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(40).pdf" style="text-decoration:none;">Visual Question Answering: A Survey of Methods and Datasets</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(41).pdf" style="text-decoration:none;">Measuring Machine Intelligence Through Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(42).pdf" style="text-decoration:none;">Towards Transparent AI Systems: Interpreting Visual Question Answering Models</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(43).pdf" style="text-decoration:none;">Graph-Structured Representations for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(44).pdf" style="text-decoration:none;">Visual Question Answering:
Datasets, Algorithms, and Future Challenges</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(45).pdf" style="text-decoration:none;">Hadamard Product for Low-rank Bilinear Pooling</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(46).pdf" style="text-decoration:none;">Dual Attention Networks for Multimodal Reasoning and Matching</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(47).pdf" style="text-decoration:none;">The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(48).pdf" style="text-decoration:none;">CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(49).pdf" style="text-decoration:none;">An Empirical Evaluation of Visual Question Answering for Novel Objects</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(50).pdf" style="text-decoration:none;">Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(51).pdf" style="text-decoration:none;">Learning to Reason: End-to-End Module Networks for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(52).pdf" style="text-decoration:none;">C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(53).pdf" style="text-decoration:none;">Inferring and Executing Programs for Visual Reasoning</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(54).pdf" style="text-decoration:none;">Survey of Visual Question Answering: Datasets and Techniques </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(55).pdf" style="text-decoration:none;">MUTAN: Multimodal Tucker Fusion for Visual Question Answering</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(56).pdf" style="text-decoration:none;">A simple neural network module for relational reasoning </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(57).pdf" style="text-decoration:none;">Visual Question Answering with Memory-Augmented Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(58).pdf" style="text-decoration:none;">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(59).pdf" style="text-decoration:none;">Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for Visual Question Answering</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(60).pdf" style="text-decoration:none;">Structured Attentions for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(61).pdf" style="text-decoration:none;">Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(62).pdf" style="text-decoration:none;">Beyond Bilinear: Generalized Multimodal Factorized High-order Pooling for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(63).pdf" style="text-decoration:none;">Robustness Analysis of Visual QA Models by Basic Questions</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(64).pdf" style="text-decoration:none;">Exploring Human-like Attention Supervision in Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(65).pdf" style="text-decoration:none;">FiLM: Visual Reasoning with a General Conditioning Layer </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(66).pdf" style="text-decoration:none;">iVQA: Inverse Visual Question Answering</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(67).pdf" style="text-decoration:none;">FigureQA: An Annotated Figure Dataset for Visual Reasoning</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(68).pdf" style="text-decoration:none;">High-Order Attention Models for Visual Question Answering</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(69).pdf" style="text-decoration:none;">A Novel Framework for Robustness Analysis of Visual QA Models</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(70).pdf" style="text-decoration:none;">Asking the Difficult Questions: Goal-Oriented Visual Question Generation via Intermediate Rewards</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(71).pdf" style="text-decoration:none;">Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(72).pdf" style="text-decoration:none;">Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(73).pdf" style="text-decoration:none;">Object-based reasoning in VQA</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(74).pdf" style="text-decoration:none;">Learning to Count Objects in Natural Images for Visual Question Answering</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(75).pdf" style="text-decoration:none;">Multimodal Explanations: Justifying Decisions and Pointing to the Evidence</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(76).pdf" style="text-decoration:none;">VizWiz Grand Challenge: Answering Visual Questions from Blind People</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(77).pdf" style="text-decoration:none;">Compositional Attention Networks for Machine Reasoning</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(78).pdf" style="text-decoration:none;">Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(79).pdf" style="text-decoration:none;">A Dataset and Architecture for Visual Reasoning with a Working Memory</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(80).pdf" style="text-decoration:none;">Visual Question Reasoning on General Dependency Tree</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(81).pdf" style="text-decoration:none;">Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(82).pdf" style="text-decoration:none;">Reciprocal Attention Fusion for Visual Question Answering</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(83).pdf" style="text-decoration:none;">R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(84).pdf" style="text-decoration:none;">Think Visually: Question Answering through Virtual Imagery</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(85).pdf" style="text-decoration:none;">Focal Visual-Text Attention for Visual Question Answering</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(86).pdf" style="text-decoration:none;">Visual Reasoning by Progressive Module Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(87).pdf" style="text-decoration:none;">CS-VQA: Visual Question Answering with Compressively Sensed Images</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(88).pdf" style="text-decoration:none;">Learning Answer Embeddings for Visual Question Answering</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(89).pdf" style="text-decoration:none;">Question Relevance in Visual Question Answering</a></li>
  
  
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(90).pdf" style="text-decoration:none;"> Pythia v0.1: the Winning Entry to the VQA Challenge 2018</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(91).pdf" style="text-decoration:none;">Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(92).pdf" style="text-decoration:none;">Multimodal Differential Network for Visual Question Generation</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(93).pdf" style="text-decoration:none;"> RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(94).pdf" style="text-decoration:none;">Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(95).pdf" style="text-decoration:none;">The Visual QA Devil in the Details: The Impact of Early Fusion and Batch Norm on CLEVR</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(96).pdf" style="text-decoration:none;">Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding</a></li> 
  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(97).pdf" style="text-decoration:none;">TallyQA: Answering Complex Counting Questions</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(98).pdf" style="text-decoration:none;">Zero-Shot Transfer VQA Dataset</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(99).pdf" style="text-decoration:none;">Explicit Bias Discovery in Visual Question Answering Models</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(100).pdf" style="text-decoration:none;">From Recognition to Cognition: Visual Commonsense Reasoning</a></li>  
  
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(101).pdf" style="text-decoration:none;">From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(102).pdf" style="text-decoration:none;">Dynamic Fusion with Intra- and Inter-modality Attention Flow for Visual Question Answering</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(103).pdf" style="text-decoration:none;">Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded </a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(104).pdf" style="text-decoration:none;">Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(105).pdf" style="text-decoration:none;">MUREL: Multimodal Relational Reasoning for Visual Question Answering</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(106).pdf" style="text-decoration:none;">GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(107).pdf" style="text-decoration:none;">Answer Them All! Toward Universal Visual Question Answering Models</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(108).pdf" style="text-decoration:none;">Relation-Aware Graph Attention Network for Visual Question Answering</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(109).pdf" style="text-decoration:none;">Towards VQA Models That Can Read</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(110).pdf" style="text-decoration:none;">Self-Critical Reasoning
for Robust Visual Question Answering </a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(111).pdf" style="text-decoration:none;">Deep Reason: A Strong Baseline for Real-World Visual Reasoning</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(112).pdf" style="text-decoration:none;">Are Disentangled Representations Helpful for Abstract Visual Reasoning?</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(113).pdf" style="text-decoration:none;">OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(114).pdf" style="text-decoration:none;">Psycholinguistics meets Continual Learning: Measuring Catastrophic Forgetting in Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(115).pdf" style="text-decoration:none;">Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(116).pdf" style="text-decoration:none;">RUBi: Reducing Unimodal Biases for Visual Question Answering</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(117).pdf" style="text-decoration:none;">Deep Modular Co-Attention Networks for Visual Question Answering</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(118).pdf" style="text-decoration:none;">Learning by Abstraction: The Neural State Machine</a></li>  
   
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(119).pdf" style="text-decoration:none;">Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(120).pdf" style="text-decoration:none;">Bilinear Graph Networks for Visual Question Answering</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(121).pdf" style="text-decoration:none;">An Empirical Study on Leveraging Scene Graphs for Visual Question Answering</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(122).pdf" style="text-decoration:none;">From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense </a></li>  
     
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(123).pdf" style="text-decoration:none;">VL-BERT: Pre-training of Generic Visual-Linguistic Representations</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(124).pdf" style="text-decoration:none;">Learning Sparse Mixture of Experts for Visual Question Answering</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(125).pdf" style="text-decoration:none;">Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(126).pdf" style="text-decoration:none;">Unified Vision-Language Pre-Training for Image Captioning and VQA</a></li> 
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(127).pdf" style="text-decoration:none;">UNITER: UNiversal Image-TExt Representation Learning</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(128).pdf" style="text-decoration:none;">Good, Better, Best: Multi-Choice VQA with Textual Distractors Generation via Policy Gradient</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(129).pdf" style="text-decoration:none;">Learning Rich Image Region Representation for Visual Question Answering</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(130).pdf" style="text-decoration:none;">Assessing the Robustness of Visual Question Answering</a></li>    
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(131).pdf" style="text-decoration:none;">Visual Question Answering on 360<sup>o</sup> Images</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(132).pdf" style="text-decoration:none;">In Defense of Grid Features for Visual Question Answering</a></li>   
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(133).pdf" style="text-decoration:none;">Component Analysis for
Visual Question Answering Architectures</a></li>     
   
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(134).pdf" style="text-decoration:none;">Counterfactual Samples Synthesizing for Robust Visual Question Answering</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(135).pdf" style="text-decoration:none;">RSVQA: Visual Question Answering for Remote Sensing Data</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(136).pdf" style="text-decoration:none;">Visual Question Answering for Cultural Heritage</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(137).pdf" style="text-decoration:none;">Linguistically Driven Graph Capsule Network for Visual Question Reasoning</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(138).pdf" style="text-decoration:none;">PathVQA: 30000+ Questions for Medical Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(139).pdf" style="text-decoration:none;">P &#8776; NP, at least in Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(140).pdf" style="text-decoration:none;">Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(141).pdf" style="text-decoration:none;"> A negative case analysis of visual grounding methods for VQA</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(142).pdf" style="text-decoration:none;">Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks</a></li>                             
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(143).pdf" style="text-decoration:none;">Deep Multimodal Neural Architecture Search</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(144).pdf" style="text-decoration:none;">A Novel Attention-based Aggregation Function to Combine Vision and Language</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(145).pdf" style="text-decoration:none;">Dynamic Language Binding in Relational Visual Reasoning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(146).pdf" style="text-decoration:none;">Visuo-Linguistic Question Answering (VLQA) Challenge</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(147).pdf" style="text-decoration:none;">Visual Question Answering with Prior Class Semantics</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(148).pdf" style="text-decoration:none;">Cross-Modality Relevance for Reasoning on Language and Vision</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(149).pdf" style="text-decoration:none;">Structured Multimodal Attentions for TextVQA</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(150).pdf" style="text-decoration:none;">Multimodal grid features and cell pointers for Scene Text Visual Question Answering</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(151).pdf" style="text-decoration:none;">M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(152).pdf" style="text-decoration:none;">Large-Scale Adversarial Training for Vision-and-Language Representation Learning </a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(153).pdf" style="text-decoration:none;">ExploringWeaknesses of VQA Models through Attribution Driven Insights</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(154).pdf" style="text-decoration:none;">Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(155).pdf" style="text-decoration:none;">Overcoming Statistical Shortcuts for Open-ended Visual Counting</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(156).pdf" style="text-decoration:none;">Self-Segregating and Coordinated-Segregating Transformer for Focused Deep Multi-Modular Network for Visual Question Answering</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(157).pdf" style="text-decoration:none;">ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through Scene Graphs</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(158).pdf" style="text-decoration:none;">DocVQA: A Dataset for VQA on Document Images</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(159).pdf" style="text-decoration:none;">The Impact of Explanations on AI Competency Prediction in VQA </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(160).pdf" style="text-decoration:none;">Scene Graph Reasoning for Visual Question Answering</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(161).pdf" style="text-decoration:none;">Visual Question Answering as a Multi-Task Problem</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(162).pdf" style="text-decoration:none;">IQ-VQA: Intelligent Visual Question Answering</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(163).pdf" style="text-decoration:none;">Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(164).pdf" style="text-decoration:none;">Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(165).pdf" style="text-decoration:none;">Contrastive Visual-Linguistic Pretraining</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(166).pdf" style="text-decoration:none;">Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(167).pdf" style="text-decoration:none;">Document Visual Question Answering Challenge 2020</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(168).pdf" style="text-decoration:none;">Visual Question Answering on Image Sets</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(169).pdf" style="text-decoration:none;">A Dataset and Baselines for Visual Question Answering on Art</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(170).pdf" style="text-decoration:none;">MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(171).pdf" style="text-decoration:none;">Regularizing Attention Networks for Anomaly Detection in Visual Question Answering</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(172).pdf" style="text-decoration:none;">Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(173).pdf" style="text-decoration:none;">X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(174).pdf" style="text-decoration:none;">Attention Guided Semantic Relationship Parsing for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(175).pdf" style="text-decoration:none;">Finding the Evidence: Localization-aware Answer Prediction for Text Visual Question Answering</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(176).pdf" style="text-decoration:none;">Interpretable Neural Computation for Real-World Compositional Visual Question Answering </a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(177).pdf" style="text-decoration:none;">Contrast and Classify: Training Robust VQA Models</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(178).pdf" style="text-decoration:none;">Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(179).pdf" style="text-decoration:none;">Answer-checking in Context: A Multi-modal Fully Attention Network for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(180).pdf" style="text-decoration:none;">Multimodal Research in Vision and Language: A Review of Current and Emerging Trends</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(181).pdf" style="text-decoration:none;">SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(182).pdf" style="text-decoration:none;">Characterizing Datasets for Social Visual Question Answering, and the New Tiny Social Dataset </a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(183).pdf" style="text-decoration:none;">Pathological Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(184).pdf" style="text-decoration:none;">Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(185).pdf" style="text-decoration:none;">MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(186).pdf" style="text-decoration:none;">Leveraging Visual Question Answering to Improve Text-to-Image Synthesis</a></li>
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(187).pdf" style="text-decoration:none;">Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View</a></li>
                             
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(188).pdf" style="text-decoration:none;">An Improved Attention for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(189).pdf" style="text-decoration:none;">Logically Consistent Loss for Visual Question Answering</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(190).pdf" style="text-decoration:none;">LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular Supervision for Visual Question Answering</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(191).pdf" style="text-decoration:none;">Interpretable Visual Reasoning via Induced Symbolic Space  </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(192).pdf" style="text-decoration:none;">XTQA: Span-Level Explanations of the Textbook Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(193).pdf" style="text-decoration:none;">Transformation Driven Visual Reasoning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(194).pdf" style="text-decoration:none;">Learning from Lexical Perturbations for Consistent Visual Question Answering</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(195).pdf" style="text-decoration:none;">Point and Ask: Incorporating Pointing into Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(196).pdf" style="text-decoration:none;">Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework of Vision-and-Language BERTs</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(197).pdf" style="text-decoration:none;">WeaQA:Weak Supervision via Captions for Visual Question Answering</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(198).pdf" style="text-decoration:none;">Generating Natural Questions from Images for Multimodal Assistants</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(199).pdf" style="text-decoration:none;">TAP: Text-Aware Pre-training for Text-VQA and Text-Caption</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(200).pdf" style="text-decoration:none;">Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(201).pdf" style="text-decoration:none;">MiniVLM: A Smaller and Faster Vision-Language Model</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(202).pdf" style="text-decoration:none;">KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(203).pdf" style="text-decoration:none;">Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(204).pdf" style="text-decoration:none;">A Closer Look at the Robustness of Vision-and-Language Pre-trained Models</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(205).pdf" style="text-decoration:none;">On Modality Bias in the TVQA Dataset</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(206).pdf" style="text-decoration:none;">KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/v(207).pdf" style="text-decoration:none;">Overcoming Language Priors with Self-supervised Learning for Visual Question Answering</a></li>


  
  
  
  
  
</ul>
