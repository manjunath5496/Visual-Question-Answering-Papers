# Visual Question Answering Papers

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(1).pdf" style="text-decoration:none;">Towards a Visual Turing Challenge</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(2).pdf" style="text-decoration:none;">Object-Centric Diagnosis of Visual Reasoning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(3).pdf" style="text-decoration:none;">Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(4).pdf" style="text-decoration:none;">Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(5).pdf" style="text-decoration:none;">UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(6).pdf" style="text-decoration:none;">ConceptBert: Concept-Aware Representation for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(7).pdf" style="text-decoration:none;">VinVL: Revisiting Visual Representations in Vision-Language Models</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(8).pdf" style="text-decoration:none;"> Understanding the Role of Scene Graphs in Visual Question Answering </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(9).pdf" style="text-decoration:none;">Recent Advances in Video Question Answering: A Review of Datasets and Methods</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(10).pdf" style="text-decoration:none;">Reasoning over Vision and Language: Exploring the Benefits of Supplemental Knowledge </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(11).pdf" style="text-decoration:none;">Latent Variable Models for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(12).pdf" style="text-decoration:none;">Visual Question Answering based on Local-Scene-Aware Referring Expression Generation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(13).pdf" style="text-decoration:none;">Answer Questions with Right Image Regions: A Visual Attention Regularization Approach</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(14).pdf" style="text-decoration:none;">Improving Visual Reasoning by Exploiting The Knowledge in Texts</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(15).pdf" style="text-decoration:none;">Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(16).pdf" style="text-decoration:none;">Unanswerable Questions about Images and Texts</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(17).pdf" style="text-decoration:none;">SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(18).pdf" style="text-decoration:none;">Learning Compositional Representation for Few-shot Visual Question Answering</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(19).pdf" style="text-decoration:none;">Visual Turing test for computer vision systems</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(20).pdf" style="text-decoration:none;">Image-Question-Linguistic Co-Attention for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(21).pdf" style="text-decoration:none;">Co-Attention Network With Question Type for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(22).pdf" style="text-decoration:none;">CGMVQA: A New Classification and Generative Model for Medical Visual Question Answering</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(23).pdf" style="text-decoration:none;">Counterfactual Vision and Language Learning</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(24).pdf" style="text-decoration:none;">Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(25).pdf" style="text-decoration:none;">Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(26).pdf" style="text-decoration:none;">Question-Guided Hybrid Convolution for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(27).pdf" style="text-decoration:none;">IQA: Visual Question Answering in Interactive Environments</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(28).pdf" style="text-decoration:none;">TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(29).pdf" style="text-decoration:none;">An Analysis of Visual Question Answering Algorithms </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(30).pdf" style="text-decoration:none;">Answer-Type Prediction for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(31).pdf" style="text-decoration:none;">DVQA: Understanding Data Visualizations via Question Answering</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(32).pdf" style="text-decoration:none;">How clever is the FiLM model, and how clever can it be?</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(33).pdf" style="text-decoration:none;">Visual Question Answering as Reading Comprehension</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(34).pdf" style="text-decoration:none;">12-in-1: Multi-Task Vision and Language Representation Learning</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(35).pdf" style="text-decoration:none;">Object-difference drived graph convolutional networks for visual question answering</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(36).pdf" style="text-decoration:none;">Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(37).pdf" style="text-decoration:none;">Chain of Reasoning for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(38).pdf" style="text-decoration:none;">Learning Conditioned Graph Structures for Interpretable Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(39).pdf" style="text-decoration:none;">ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(40).pdf" style="text-decoration:none;">Visual Question Answering with Question Representation Update (QRU)</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(41).pdf" style="text-decoration:none;">Multimodal Learning and Reasoning for Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(42).pdf" style="text-decoration:none;">SQuINTing at VQA Models:
Introspecting VQA Models with Sub-Questions</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(43).pdf" style="text-decoration:none;">Learning Visual Knowledge Memory Networks for Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(44).pdf" style="text-decoration:none;">VQA with No Questions-Answers Training</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(45).pdf" style="text-decoration:none;">Data Augmentation for Visual Question Answering</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(46).pdf" style="text-decoration:none;">Visual Commonsense R-CNN</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(47).pdf" style="text-decoration:none;">TA-Student VQA: Multi-Agents Training by Self-Questioning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(48).pdf" style="text-decoration:none;">Deep Attention Neural Tensor Network for Visual Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Question-Answering-Papers/blob/master/q(49).pdf" style="text-decoration:none;">Multi-level Attention Networks for Visual Question Answering</a></li>
                              
</ul>
